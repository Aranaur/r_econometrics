<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title> 3 Проста лінійна регресія | r_econometrics.knit</title>
<meta name="author" content="Ігор Мірошниченко">
<meta name="description" content="Економетрика - це дисципліна, яка займається дослідженням взаємозв’язків між даними. Для цього нам знадобиться знання статистики, математики, економіки. Це може допомогти вирішити дві головні...">
<meta name="generator" content="bookdown 0.26 with bs4_book()">
<meta property="og:title" content=" 3 Проста лінійна регресія | r_econometrics.knit">
<meta property="og:type" content="book">
<meta property="og:description" content="Економетрика - це дисципліна, яка займається дослідженням взаємозв’язків між даними. Для цього нам знадобиться знання статистики, математики, економіки. Це може допомогти вирішити дві головні...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content=" 3 Проста лінійна регресія | r_econometrics.knit">
<meta name="twitter:description" content="Економетрика - це дисципліна, яка займається дослідженням взаємозв’язків між даними. Для цього нам знадобиться знання статистики, математики, економіки. Це може допомогти вирішити дві головні...">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.3.1/transition.js"></script><script src="libs/bs3compat-0.3.1/tabs.js"></script><script src="libs/bs3compat-0.3.1/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><link rel="stylesheet" href="style.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title=""><span style="font-size: 14px">ОСНОВИ ЕКОНОМЕТРИКИ В R
</span></a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Зміст</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Основи економетрики в R</a></li>
<li><a class="" href="introR.html"><span class="header-section-number">1</span> Вступ до R</a></li>
<li><a class="" href="dplyr.html"><span class="header-section-number">2</span> Маніпуляції з даними за допомогою dplyr і не тільки</a></li>
<li><a class="active" href="simple_regression.html"><span class="header-section-number">3</span> Проста лінійна регресія</a></li>
<li><a class="" href="multiple_regression.html"><span class="header-section-number">4</span> Множинна лінійна регресія</a></li>
<li><a class="" href="multicollinearity.html"><span class="header-section-number">5</span> Мультиколінеарність</a></li>
<li><a class="" href="heteroskedasticity.html"><span class="header-section-number">6</span> Гетероскедастичність</a></li>
<li><a class="" href="regularization.html"><span class="header-section-number">7</span> Регуляризація</a></li>
<li><a class="" href="time_series.html"><span class="header-section-number">8</span> Регресійний аналіз часових рядів</a></li>
<li><a class="" href="glm.html"><span class="header-section-number">9</span> GLM</a></li>
<li><a class="" href="references.html">Література</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/aranaur/r_econometrics">Переглянути код <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="simple_regression" class="section level1" number="3">
<h1>
<span class="header-section-number"> 3</span> Проста лінійна регресія<a class="anchor" aria-label="anchor" href="#simple_regression"><i class="fas fa-link"></i></a>
</h1>
<p><strong>Економетрика</strong> - це дисципліна, яка займається дослідженням взаємозв’язків між даними. Для цього нам знадобиться знання статистики, математики, економіки. Це може допомогти вирішити дві головні задачі дослідження:</p>
<ul>
<li><p>пояснити зв’язки: визначити які показники впливають сильніше на певні процеси, а які менше.</p></li>
<li><p>будувати прогнози: як буде розвиватися процес в подальшому або при інших умовах.</p></li>
</ul>
<p>Уявіть, що вам необхідно оцінити ефективність витрат рекламної компанії, тенденцію розвитку витрат виробництва, прогноз валового внутрішнього продукту тощо. На кожне з цих завдань може допомогти знайти відповідь економетрика, хоча з точки зору прогнозної сили, напевно, слід піти далі і звернутися до алгоритмів машинного навчання або нейронних мереж, хоча й там є свої особливості. На мою думку, економетрика на рівні зі статистикою - це чудовий фундамент для подальшого вивчення машинного навчання.</p>
<p>Для економетричного дослідження необхідно будувати математичні моделі - спрощений варіант реальних об’єктів дослідження. Виглядають вони частіше за все, як певні рівняння, наприклад опишемо залежність заробітної плати робітника від його освіти, досвіду роботи та навичок. Таку залежність можна описати наступним чином:</p>
<p><span class="math display" id="eq:reg">\[
y = f(x_1, x_2, x_3, \dots, x_n),
\tag{3.1}
\]</span>
де
<span class="math inline">\(y\)</span> — заробітна плата,
<span class="math inline">\(x_1\)</span> — рівень освіти,
<span class="math inline">\(x_2\)</span> — досвід роботи,
<span class="math inline">\(x_3\)</span> — навички (знання мов програмування, статистики тощо),
<span class="math inline">\(x_n\)</span> — інші показники,
<span class="math inline">\(f\)</span> — функція залежності: описує яким саме чином <span class="math inline">\(x_i\)</span> впливають на <span class="math inline">\(y\)</span>.</p>
<p>Змінна <span class="math inline">\(y\)</span>, яку ми намагаємось пояснити, називається <strong>залежною</strong>, а змінні <span class="math inline">\(x_i\)</span>, за допомогою яких ми намагаємось пояснити або спрогнозувати залежну змінну, називають <strong>незалежними</strong>. Хоча можуть зустрічатися і альтернативні визначення:</p>
<div class="inline-table"><table class="table table-sm">
<thead><tr class="header">
<th align="center"><strong>Y</strong></th>
<th align="center"><strong>X</strong></th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="center">Залежна змінна</td>
<td align="center">Незалежна змінна</td>
</tr>
<tr class="even">
<td align="center">Пояснювана змінна</td>
<td align="center">Пояснювальна змінна</td>
</tr>
<tr class="odd">
<td align="center">Відгук</td>
<td align="center">Контрольна змінна</td>
</tr>
<tr class="even">
<td align="center">Прогнозована змінна</td>
<td align="center">Предиктор</td>
</tr>
<tr class="odd">
<td align="center">Регресант</td>
<td align="center">Регресор</td>
</tr>
<tr class="even">
<td align="center"></td>
<td align="center">Коваріат</td>
</tr>
</tbody>
</table></div>
<p>Зверніть увагу, що ми суб’єктивно оголосили, що на заробітну плату впливають зазначені показники. При альтернативних дослідженні і форма залежності, і перелік змінних може бути іншим. Та й взагалі, можливо ми захочемо пояснити вже рівень освіти за допомогою заробітної плати, досвіду роботи і навичок. Все це ми визначаємо на основі своїх знань, досвіду та доступної інформації.</p>
<p>В якості джерел даних можуть виступати:</p>
<ul>
<li>
<em>Перехресні дані</em>: дані зібрані по різним об’єктам дослідження (персонал, компанії, держави, сфери тощо). Часто такі дані були зібрані за допомогою простої випадкової вибірки.</li>
</ul>
<div class="sourceCode" id="cb134"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://tidyverse.tidyverse.org">tidyverse</a></span><span class="op">)</span>
<span class="va">starwars</span>
<span class="co">## # A tibble: 87 x 14</span>
<span class="co">##    name     height  mass hair_color skin_color eye_color birth_year sex   gender</span>
<span class="co">##    &lt;chr&gt;     &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; </span>
<span class="co">##  1 Luke Sk~    172    77 blond      fair       blue            19   male  mascu~</span>
<span class="co">##  2 C-3PO       167    75 &lt;NA&gt;       gold       yellow         112   none  mascu~</span>
<span class="co">##  3 R2-D2        96    32 &lt;NA&gt;       white, bl~ red             33   none  mascu~</span>
<span class="co">##  4 Darth V~    202   136 none       white      yellow          41.9 male  mascu~</span>
<span class="co">##  5 Leia Or~    150    49 brown      light      brown           19   fema~ femin~</span>
<span class="co">##  6 Owen La~    178   120 brown, gr~ light      blue            52   male  mascu~</span>
<span class="co">##  7 Beru Wh~    165    75 brown      light      blue            47   fema~ femin~</span>
<span class="co">##  8 R5-D4        97    32 &lt;NA&gt;       white, red red             NA   none  mascu~</span>
<span class="co">##  9 Biggs D~    183    84 black      light      brown           24   male  mascu~</span>
<span class="co">## 10 Obi-Wan~    182    77 auburn, w~ fair       blue-gray       57   male  mascu~</span>
<span class="co">## # ... with 77 more rows, and 5 more variables: homeworld &lt;chr&gt;, species &lt;chr&gt;,</span>
<span class="co">## #   films &lt;list&gt;, vehicles &lt;list&gt;, starships &lt;list&gt;</span></code></pre></div>
<ul>
<li>
<em>Часові ряди</em>: дані по одному чи декількох об’єктах дослідження впродовж певного періоду часу (курси валют, ВВП, пасажиропотік тощо). Головною особливістю таких даних виступає часова впорядкованість (від минулого до сучасного) та частота даних (однаковий інтервал запису даних).</li>
</ul>
<div class="sourceCode" id="cb135"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">economics</span>
<span class="co">## # A tibble: 574 x 6</span>
<span class="co">##    date         pce    pop psavert uempmed unemploy</span>
<span class="co">##    &lt;date&gt;     &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;</span>
<span class="co">##  1 1967-07-01  507. 198712    12.6     4.5     2944</span>
<span class="co">##  2 1967-08-01  510. 198911    12.6     4.7     2945</span>
<span class="co">##  3 1967-09-01  516. 199113    11.9     4.6     2958</span>
<span class="co">##  4 1967-10-01  512. 199311    12.9     4.9     3143</span>
<span class="co">##  5 1967-11-01  517. 199498    12.8     4.7     3066</span>
<span class="co">##  6 1967-12-01  525. 199657    11.8     4.8     3018</span>
<span class="co">##  7 1968-01-01  531. 199808    11.7     5.1     2878</span>
<span class="co">##  8 1968-02-01  534. 199920    12.3     4.5     3001</span>
<span class="co">##  9 1968-03-01  544. 200056    11.7     4.1     2877</span>
<span class="co">## 10 1968-04-01  544  200208    12.3     4.6     2709</span>
<span class="co">## # ... with 564 more rows</span></code></pre></div>
<ul>
<li>
<em>Панельні дані</em>: поєднуть в собі перехресні дані та часові ряди, вони показують, як об’єкти дослідження змінювались з часом.</li>
</ul>
<div class="sourceCode" id="cb136"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/jennybc/gapminder">gapminder</a></span><span class="op">)</span>
<span class="va">gapminder</span>
<span class="co">## # A tibble: 1,704 x 6</span>
<span class="co">##    country     continent  year lifeExp      pop gdpPercap</span>
<span class="co">##    &lt;fct&gt;       &lt;fct&gt;     &lt;int&gt;   &lt;dbl&gt;    &lt;int&gt;     &lt;dbl&gt;</span>
<span class="co">##  1 Afghanistan Asia       1952    28.8  8425333      779.</span>
<span class="co">##  2 Afghanistan Asia       1957    30.3  9240934      821.</span>
<span class="co">##  3 Afghanistan Asia       1962    32.0 10267083      853.</span>
<span class="co">##  4 Afghanistan Asia       1967    34.0 11537966      836.</span>
<span class="co">##  5 Afghanistan Asia       1972    36.1 13079460      740.</span>
<span class="co">##  6 Afghanistan Asia       1977    38.4 14880372      786.</span>
<span class="co">##  7 Afghanistan Asia       1982    39.9 12881816      978.</span>
<span class="co">##  8 Afghanistan Asia       1987    40.8 13867957      852.</span>
<span class="co">##  9 Afghanistan Asia       1992    41.7 16317921      649.</span>
<span class="co">## 10 Afghanistan Asia       1997    41.8 22227415      635.</span>
<span class="co">## # ... with 1,694 more rows</span></code></pre></div>
<p>Функція залежності (<span class="math inline">\(f\)</span>) може мати різну форму та характер. Ми не знаємо її заздалегідь і намагаємось підібрати найкращий варіант з декількох альтернатив.</p>
<div id="проста-лінійна-регресія" class="section level2" number="3.1">
<h2>
<span class="header-section-number">3.1</span> Проста лінійна регресія<a class="anchor" aria-label="anchor" href="#%D0%BF%D1%80%D0%BE%D1%81%D1%82%D0%B0-%D0%BB%D1%96%D0%BD%D1%96%D0%B9%D0%BD%D0%B0-%D1%80%D0%B5%D0%B3%D1%80%D0%B5%D1%81%D1%96%D1%8F"><i class="fas fa-link"></i></a>
</h2>
<p><strong>Проста лінійна регресія</strong> — це модель, яка пояснює залежність між <em>двома змінними</em> за допомогою <em>лінійного взаємозв’язку</em>.</p>
<p>Роботу такої регресії краще пояснити на прикладі. В нашому розпорядженні є набір даних про вагу та зріст вибірки чоловіків та жінок:</p>
<div class="sourceCode" id="cb137"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">weight_height</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://readr.tidyverse.org/reference/read_delim.html">read_csv</a></span><span class="op">(</span><span class="st">"https://raw.githubusercontent.com/Aranaur/datasets/main/datasets/weight-height.csv"</span><span class="op">)</span>

<span class="va">weight_height</span>
<span class="co">## # A tibble: 10,000 x 3</span>
<span class="co">##    Gender Height Weight</span>
<span class="co">##    &lt;chr&gt;   &lt;dbl&gt;  &lt;dbl&gt;</span>
<span class="co">##  1 Male     73.8   242.</span>
<span class="co">##  2 Male     68.8   162.</span>
<span class="co">##  3 Male     74.1   213.</span>
<span class="co">##  4 Male     71.7   220.</span>
<span class="co">##  5 Male     69.9   206.</span>
<span class="co">##  6 Male     67.3   152.</span>
<span class="co">##  7 Male     68.8   184.</span>
<span class="co">##  8 Male     68.3   168.</span>
<span class="co">##  9 Male     67.0   176.</span>
<span class="co">## 10 Male     63.5   156.</span>
<span class="co">## # ... with 9,990 more rows</span></code></pre></div>
<p>Конвертуємо значення в кілограми і сантиметри та візуалізуємо підвибірку по чоловікам:</p>
<div class="sourceCode" id="cb138"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># фіксуємо генератор випадкових величин</span>
<span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">2022</span><span class="op">)</span>

<span class="va">male</span> <span class="op">&lt;-</span> <span class="va">weight_height</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
  <span class="co"># беремо тільки чоловіків</span>
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/filter.html">filter</a></span><span class="op">(</span><span class="va">Gender</span> <span class="op">==</span> <span class="st">"Male"</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span>
  <span class="co"># формуємо випадкову підвибірку</span>
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/slice.html">slice_sample</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">100</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
  <span class="co"># конвертуємо значення</span>
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>Height_kg <span class="op">=</span> <span class="va">Height</span> <span class="op">*</span> <span class="fl">2.54</span>,
         Weight_cm <span class="op">=</span> <span class="va">Weight</span> <span class="op">*</span> <span class="fl">0.45</span><span class="op">)</span>

<span class="co"># візуалізуємо</span>
<span class="va">male</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span><span class="va">Height_kg</span>, <span class="va">Weight_cm</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>x <span class="op">=</span> <span class="st">"Зріст (см)"</span>,
       y <span class="op">=</span> <span class="st">"Вага (кг)"</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="r_econometrics_files/figure-html/unnamed-chunk-8-1.png" width="100%"></div>
<p>Припустимо, що взаємозв’язок між вагою і зростом - лінійний. Такі випадки на практиці досить рідко зустрічаються і пізніше ми познайомимось з іншими варіантами.</p>
<p>Рівняння прямої виглядає наступним чином:
<span class="math display" id="eq:lmreg">\[
y_i = \beta_0 + \beta_1x_i + u_i
\tag{3.2}
\]</span>
Підставимо конкретні змінні у рівняння, отримаємо:
<span class="math display" id="eq:malereg">\[
Weight_i = \beta_0 + \beta_1Height_i + u_i
\tag{3.3}
\]</span>
Рівняння <a href="simple_regression.html#eq:lmreg">(3.2)</a> та <a href="simple_regression.html#eq:malereg">(3.3)</a> називаються простою лінійною регресією або парною лінійною регресією.</p>
<p>Розглянемо складові рівняння <a href="simple_regression.html#eq:lmreg">(3.2)</a>:</p>
<ul>
<li><p><span class="math inline">\(y\)</span>: залежна змінна.</p></li>
<li><p><span class="math inline">\(\beta_0\)</span>: вільний параметр моделі, який відповідає за точку перетину прямої з вістю ординат.</p></li>
<li><p><span class="math inline">\(\beta_1\)</span>: залежний параметр моделі, який відповідає за кут нахилу прямої.</p></li>
<li><p><span class="math inline">\(x\)</span>: незалежна змінна.</p></li>
<li><p><span class="math inline">\(u\)</span>: залишки моделі.</p></li>
</ul>
<p>Для того щоб тримати рівняння прямої, нам необхідно підібрати значення параметрів моделі: <span class="math inline">\(\hat{\beta_0}\)</span> та <span class="math inline">\(\hat{\beta_1}\)</span>. Що значать “кришки” <span class="math inline">\(^\)</span> над коєфіціентами? Справа в тому, що в нашому розпорядженні є тільки певна вибірка даних і провести ідеальну пряму через всі точки неможливо. Тому нам необхідно розрахувати оцінки параметрів моделі, які будуть задовільняти нас.</p>
<p>Отже рівняння моделі набуває вигляду:
<span class="math display" id="eq:lmreg1">\[
\hat{y_i} = \hat{\beta_0} + \hat{\beta_1}x_i
\tag{3.4}
\]</span>
або для нашого прикладу
<span class="math display" id="eq:malereg1">\[
\hat{Weight_i} = \hat{\beta_0} + \hat{\beta_1}Height_i
\tag{3.5}
\]</span>
Давайте для початку проведемо пряму, яка відповідає середньому значенню ваги чоловіків по вибірці:</p>
<div class="sourceCode" id="cb139"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">male</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span><span class="va">Height_kg</span>, <span class="va">Weight_cm</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_abline.html">geom_hline</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>yintercept <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">Weight_cm</span><span class="op">)</span><span class="op">)</span>, color <span class="op">=</span> <span class="st">"blue"</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>x <span class="op">=</span> <span class="st">"Зріст (см)"</span>,
       y <span class="op">=</span> <span class="st">"Вага (кг)"</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="r_econometrics_files/figure-html/midline-1.png" width="100%"></div>
<p>Очевидно, що така “модель” є неоптимальною і вона має значні залишки: відхилення модельних значень від фактичних</p>
<div class="sourceCode" id="cb140"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">male</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>fit1 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">Weight_cm</span><span class="op">)</span>,
         resid1 <span class="op">=</span> <span class="va">Weight_cm</span> <span class="op">-</span> <span class="va">fit1</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span><span class="va">Height_kg</span>, <span class="va">Weight_cm</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_abline.html">geom_hline</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>yintercept <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">Weight_cm</span><span class="op">)</span><span class="op">)</span>, color <span class="op">=</span> <span class="st">"blue"</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_segment.html">geom_segment</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>xend <span class="op">=</span> <span class="va">Height_kg</span>, yend <span class="op">=</span> <span class="va">fit1</span><span class="op">)</span>, alpha <span class="op">=</span> <span class="fl">0.2</span>, color <span class="op">=</span> <span class="st">"red"</span><span class="op">)</span> <span class="op">+</span> 
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>x <span class="op">=</span> <span class="st">"Зріст (см)"</span>,
       y <span class="op">=</span> <span class="st">"Вага (кг)"</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="r_econometrics_files/figure-html/resid-1.png" width="100%"></div>
<p>Позитивні відхилення розташовані вище модельних значень, а від’ємні - нижче.</p>
<div class="inline-figure">Давайте побудуємо декілька альтернативних прямих
<img src="r_econometrics_files/figure-html/fit2-1.png" width="100%">
</div>
<p>Такі моделі вже мають значно менші відхилення. Але вони були побудовані “на око” без точних математичних розрахунків. Як провести оптимізацію процесу підбору моделі? Для цього ми вводимо функцію втрат (<em>loss function</em>), мінімізуючи котру ми будемо підбирати оптимальні значення <span class="math inline">\(\hat{\beta_0}\)</span> та <span class="math inline">\(\hat{\beta_1}\)</span>. На перший погляд здається, що непоганою ідеєю було б розрахувати суму похибок <span class="math inline">\(\sum\limits^{n}_{i=1}{u_i}\)</span> для всіх альтернатив та обрати модель з найменшим значенням. Але такий підхід має значний недолік: представимо, що ми побудували дві моделі і отримали залишки <span class="math inline">\(u_{m1} = (-10, -5, 5, 10)\)</span> для першої та <span class="math inline">\(u_{m2} = (-100, -50, 50, 100)\)</span> для другої моделі. Сума залишків для обох моделей дорівнює нулю, але це не значит, що моделі не помиляються. Позитивні та негативні похибки компенсують один одного, при цьому коливання похибок другої моделі значно більші. Тож такий підхід нам не підходить.</p>
<p>Тому для оцінювання параметрів моделі в лінійній регресії пропонується використовувати <strong>метод найменших квадратів</strong> (МНК, <em>ordinary least squares, OLS</em>): серед альтернатив обbраємо ту, для котрої сума квадратів відхилення буде мінімальною.
<span class="math display" id="eq:ols">\[
\sum\limits^{n}_{i=1}{u_i^2} = u_1^2 + u_2^2 + \dots + u_n^2 \rightarrow min
\tag{3.6}
\]</span>
Чому слід брати квадрат відхилення, а не абсолютні значення <span class="math inline">\(\left |{u_1}\right | + \left |{u_2}\right | + \dots + \left |{u_n}\right |\)</span>? Такий підхід має значний недолік: абсолютні значення не мають неперервної похідної, що робить таку функцію негладкою. До того ж квадрат похибок “штрафують” модель сильніше з більших відхилень. Як альтернативу можна обрати інші парні степені похибок, такі як 4 або 6, але і там є певні складнощі. Тому на практиці частіше за всі інші альтернативи обирають МНК.</p>
<p>Подивимось, як працює мінімізація суми квадратів залишків.
<span class="math display" id="eq:sumerror">\[
\sum\limits^{n}_{i=1}{u_i^2} = \sum\limits^{n}_{i=1}(y_i - \hat{\beta_0} - \hat{\beta_1}x_i)^2 \rightarrow min
\tag{3.7}
\]</span>
Візьмемо похідні по <span class="math inline">\(\hat{\beta_0}\)</span> та <span class="math inline">\(\hat{\beta_1}\)</span>:
<span class="math display" id="eq:pohid">\[
\left\{\begin{matrix}
 -2\sum\limits^{n}_{i=1}(y_i - \hat{\beta_0} - \hat{\beta_1}x_i) = 0 &amp; \\ 
-2\sum\limits^{n}_{i=1}x_i(y_i - \hat{\beta_0} - \hat{\beta_1}x_i) = 0 &amp; 
\end{matrix}\right.
\tag{3.8}
\]</span></p>
<p>Розкриємо дужки першого рівняння:
<span class="math display" id="eq:pohid2">\[
\left\{\begin{matrix}
\sum\limits^{n}_{i=1}y_i - n\hat{\beta_0} - \hat{\beta_1}x_i = 0 &amp; \\ 
\sum\limits^{n}_{i=1}x_i(y_i - \hat{\beta_0} - \hat{\beta_1}x_i) = 0 &amp; 
\end{matrix}\right.
\tag{3.9}
\]</span></p>
<p>Поділимо перше рівняння на <span class="math inline">\(n\)</span>:
<span class="math display" id="eq:pohid3">\[
\left\{\begin{matrix}
\overline{y} - \hat{\beta_0} - \hat{\beta_1}\overline{x} = 0 &amp; \\ 
\sum\limits^{n}_{i=1}x_i(y_i - \hat{\beta_0} - \hat{\beta_1}x_i) = 0 &amp; 
\end{matrix}\right.
\tag{3.10}
\]</span>
З першого рівняння виразимо <span class="math inline">\(\hat{\beta_0}\)</span> і підставимо у друге:
<span class="math display" id="eq:pohid4">\[
\left\{\begin{matrix}
\hat{\beta_0} = \overline{y} - \hat{\beta_1}\overline{x} &amp; \\ 
\sum\limits^{n}_{i=1}x_i(y_i - (\overline{y} - \hat{\beta_1}\overline{x}) - \hat{\beta_1}x_i) = 0 &amp; 
\end{matrix}\right.
\tag{3.11}
\]</span>
Розкриємо дужки у другому рівнянні:
<span class="math display" id="eq:pohid5">\[
\left\{\begin{matrix}
\hat{\beta_0} = \overline{y} - \hat{\beta_1}\overline{x} &amp; \\ 
\sum\limits^{n}_{i=1}x_i(y_i - \overline{y}) =  \hat{\beta_1}\sum\limits^{n}_{i=1}x_i(x_i - \overline{x}) 
\end{matrix}\right.
\tag{3.12}
\]</span>
Оскільки
<span class="math display">\[\sum\limits^{n}_{i=1}x_i(y_i - \overline{y}) = \sum\limits^{n}_{i=1}(x_i - \overline{x})^2\]</span>
та
<span class="math display">\[\sum\limits^{n}_{i=1}x_i(y_i - \overline{y}) = \sum\limits^{n}_{i=1}(x_i - \overline{x})(y_i - \overline{y}),\]</span>
тоді за умови
<span class="math display" id="eq:pohid6">\[
\sum\limits^{n}_{i=1}(x_i - \overline{x})^2 &gt; 0
\tag{3.13}
\]</span>
оцінки параметрів моделі <span class="math inline">\(\hat{\beta_0}\)</span> та <span class="math inline">\(\hat{\beta_1}\)</span> будуть дорівнювати:
<span class="math display" id="eq:pohid7">\[
\left\{\begin{matrix}
\hat{\beta_0} = \overline{y} - \hat{\beta_1}\overline{x} &amp; \\ 
\hat{\beta_1} = \frac{\sum\limits^{n}_{i=1}(x_i - \overline{x})(y_i - \overline{y})}{\sum\limits^{n}_{i=1}(x_i - \overline{x})^2} = \frac{\overline{xy} - \overline{x}\overline{y}}{\overline{x^2} - \overline{x}^2}
\end{matrix}\right.
\tag{3.14}
\]</span>
Давайте поетапно розрахуємо значення <span class="math inline">\(\hat{\beta_0}\)</span> та <span class="math inline">\(\hat{\beta_1}\)</span> для нашого прикладу з вагою і зростом:</p>
<div class="sourceCode" id="cb141"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">male</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="va">Height_kg</span>, <span class="va">Weight_cm</span><span class="op">)</span>
<span class="co">## # A tibble: 100 x 2</span>
<span class="co">##    Height_kg Weight_cm</span>
<span class="co">##        &lt;dbl&gt;     &lt;dbl&gt;</span>
<span class="co">##  1      182.      89.4</span>
<span class="co">##  2      174.      80.9</span>
<span class="co">##  3      175.      83.9</span>
<span class="co">##  4      182.      86.6</span>
<span class="co">##  5      177.      82.9</span>
<span class="co">##  6      184.     101. </span>
<span class="co">##  7      185.      84.8</span>
<span class="co">##  8      169.      79.2</span>
<span class="co">##  9      170.      74.0</span>
<span class="co">## 10      187.      94.5</span>
<span class="co">## # ... with 90 more rows</span></code></pre></div>
<p>Додамо розрахункові значення <span class="math inline">\(Height_{kg}^2\)</span> та <span class="math inline">\(Height_{kg}*Weight_{cm}\)</span>:</p>
<div class="sourceCode" id="cb142"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">male</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="va">Height_kg</span>, <span class="va">Weight_cm</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>Height_kg_sq <span class="op">=</span> <span class="va">Height_kg</span> <span class="op">^</span> <span class="fl">2</span>,
         Height_Weight <span class="op">=</span> <span class="va">Height_kg</span> <span class="op">*</span> <span class="va">Weight_cm</span><span class="op">)</span>
<span class="co">## # A tibble: 100 x 4</span>
<span class="co">##    Height_kg Weight_cm Height_kg_sq Height_Weight</span>
<span class="co">##        &lt;dbl&gt;     &lt;dbl&gt;        &lt;dbl&gt;         &lt;dbl&gt;</span>
<span class="co">##  1      182.      89.4       33197.        16286.</span>
<span class="co">##  2      174.      80.9       30197.        14062.</span>
<span class="co">##  3      175.      83.9       30469.        14644.</span>
<span class="co">##  4      182.      86.6       33302.        15799.</span>
<span class="co">##  5      177.      82.9       31233.        14651.</span>
<span class="co">##  6      184.     101.        33907.        18675.</span>
<span class="co">##  7      185.      84.8       34065.        15647.</span>
<span class="co">##  8      169.      79.2       28566.        13385.</span>
<span class="co">##  9      170.      74.0       28917.        12583.</span>
<span class="co">## 10      187.      94.5       34841.        17637.</span>
<span class="co">## # ... with 90 more rows</span></code></pre></div>
<p>Знайдемо середнє значення для кожного стовпчика:</p>
<div class="sourceCode" id="cb143"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">male</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="va">Height_kg</span>, <span class="va">Weight_cm</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>Height_kg_sq <span class="op">=</span> <span class="va">Height_kg</span> <span class="op">^</span> <span class="fl">2</span>,
         Height_Weight <span class="op">=</span> <span class="va">Height_kg</span> <span class="op">*</span> <span class="va">Weight_cm</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/summarise.html">summarise</a></span><span class="op">(</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/across.html">across</a></span><span class="op">(</span><span class="va">Height_kg</span><span class="op">:</span><span class="va">Height_Weight</span>,
            <span class="va">mean</span>,
            .names <span class="op">=</span> <span class="st">"mean_{.col}"</span><span class="op">)</span><span class="op">)</span>
<span class="co">## # A tibble: 1 x 4</span>
<span class="co">##   mean_Height_kg mean_Weight_cm mean_Height_kg_sq mean_Height_Weight</span>
<span class="co">##            &lt;dbl&gt;          &lt;dbl&gt;             &lt;dbl&gt;              &lt;dbl&gt;</span>
<span class="co">## 1           176.           83.8            30892.             14780.</span></code></pre></div>
<p>Тепер можемо розрахувати оцінки параметрів моделі:</p>
<div class="sourceCode" id="cb144"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">male</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="va">Height_kg</span>, <span class="va">Weight_cm</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>Height_kg_sq <span class="op">=</span> <span class="va">Height_kg</span> <span class="op">^</span> <span class="fl">2</span>,
         Height_Weight <span class="op">=</span> <span class="va">Height_kg</span> <span class="op">*</span> <span class="va">Weight_cm</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/summarise.html">summarise</a></span><span class="op">(</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/across.html">across</a></span><span class="op">(</span><span class="va">Height_kg</span><span class="op">:</span><span class="va">Height_Weight</span>,
            <span class="va">mean</span>,
            .names <span class="op">=</span> <span class="st">"mean_{.col}"</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">transmute</a></span><span class="op">(</span>beta_1 <span class="op">=</span> <span class="op">(</span><span class="va">mean_Height_Weight</span> <span class="op">-</span> <span class="va">mean_Height_kg</span> <span class="op">*</span> <span class="va">mean_Weight_cm</span><span class="op">)</span><span class="op">/</span><span class="op">(</span><span class="va">mean_Height_kg_sq</span> <span class="op">-</span> <span class="va">mean_Height_kg</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span>,
            beta_0 <span class="op">=</span> <span class="va">mean_Weight_cm</span> <span class="op">-</span> <span class="va">beta_1</span> <span class="op">*</span> <span class="va">mean_Height_kg</span><span class="op">)</span>
<span class="co">## # A tibble: 1 x 2</span>
<span class="co">##   beta_1 beta_0</span>
<span class="co">##    &lt;dbl&gt;  &lt;dbl&gt;</span>
<span class="co">## 1   1.02  -96.0</span></code></pre></div>
<p>Отже рівняння простої лінійної регресії для нашого прикладу буде виглядати:
<span class="math display">\[\hat{y_i} = -96 + 1.02 * \hat{x}\]</span>
Звичайно, на практиці оцінки параметрів моделі за МНК розраховуються за допомогою комп’ютера. Для цього, в R є функція <code><a href="https://rdrr.io/r/stats/lm.html">lm()</a></code>, де першим аргументом вказується формула залежності, а другим набір даних:</p>
<div class="sourceCode" id="cb145"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># у формулі ліворуч від ~ знаходиться залежна змінна</span>
<span class="co"># праворуч від ~ незалежні змінні</span>
<span class="va">male_ols</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">Weight_cm</span> <span class="op">~</span> <span class="va">Height_kg</span>, data <span class="op">=</span> <span class="va">male</span><span class="op">)</span>
<span class="va">male_ols</span>
<span class="co">## </span>
<span class="co">## Call:</span>
<span class="co">## lm(formula = Weight_cm ~ Height_kg, data = male)</span>
<span class="co">## </span>
<span class="co">## Coefficients:</span>
<span class="co">## (Intercept)    Height_kg  </span>
<span class="co">##     -95.999        1.024</span></code></pre></div>
<p>Результат моделі <code>male_ols</code> зберігається у вигляді списку, з якого ми можемо отримати залишки, параметри моделі, модельні значення тощо:</p>
<div class="sourceCode" id="cb146"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Оцінки параметрів моделі</span>
<span class="va">male_ols</span><span class="op">$</span><span class="va">coefficients</span>
<span class="co">## (Intercept)   Height_kg </span>
<span class="co">##  -95.998717    1.024054</span>
<span class="co"># Модельні значення в тібблі</span>
<span class="fu"><a href="https://tibble.tidyverse.org/reference/as_tibble.html">as_tibble</a></span><span class="op">(</span><span class="va">male_ols</span><span class="op">$</span><span class="va">fitted.values</span><span class="op">)</span>
<span class="co">## # A tibble: 100 x 1</span>
<span class="co">##    value</span>
<span class="co">##    &lt;dbl&gt;</span>
<span class="co">##  1  90.6</span>
<span class="co">##  2  82.0</span>
<span class="co">##  3  82.8</span>
<span class="co">##  4  90.9</span>
<span class="co">##  5  85.0</span>
<span class="co">##  6  92.6</span>
<span class="co">##  7  93.0</span>
<span class="co">##  8  77.1</span>
<span class="co">##  9  78.1</span>
<span class="co">## 10  95.1</span>
<span class="co">## # ... with 90 more rows</span></code></pre></div>
<p>Побудуємо візуалізацію отриманих результатів за допомогою <code>ggplot2</code></p>
<div class="sourceCode" id="cb147"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">male</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span><span class="va">Height_kg</span>, <span class="va">Weight_cm</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_smooth.html">geom_smooth</a></span><span class="op">(</span>method <span class="op">=</span> <span class="st">"lm"</span>, se <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>x <span class="op">=</span> <span class="st">"Зріст (см)"</span>,
       y <span class="op">=</span> <span class="st">"Вага (кг)"</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="r_econometrics_files/figure-html/olsplot1-1.png" width="100%"></div>
<p>або</p>
<div class="sourceCode" id="cb148"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">male</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>fit_ols <span class="op">=</span> <span class="va">male_ols</span><span class="op">$</span><span class="va">fitted.values</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span><span class="va">Height_kg</span>, <span class="va">Weight_cm</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html">geom_line</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span><span class="va">Height_kg</span>, <span class="va">fit_ols</span><span class="op">)</span>, color <span class="op">=</span> <span class="st">"blue"</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>x <span class="op">=</span> <span class="st">"Зріст (см)"</span>,
       y <span class="op">=</span> <span class="st">"Вага (кг)"</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="r_econometrics_files/figure-html/olsplot2-1.png" width="100%"></div>
</div>
<div id="властивості-модельних-значень-та-залишків" class="section level2" number="3.2">
<h2>
<span class="header-section-number">3.2</span> Властивості модельних значень та залишків<a class="anchor" aria-label="anchor" href="#%D0%B2%D0%BB%D0%B0%D1%81%D1%82%D0%B8%D0%B2%D0%BE%D1%81%D1%82%D1%96-%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D1%8C%D0%BD%D0%B8%D1%85-%D0%B7%D0%BD%D0%B0%D1%87%D0%B5%D0%BD%D1%8C-%D1%82%D0%B0-%D0%B7%D0%B0%D0%BB%D0%B8%D1%88%D0%BA%D1%96%D0%B2"><i class="fas fa-link"></i></a>
</h2>
<p>Залишки регресії, які отримані за допомогою МНК мають декілька властивостей:</p>
<ol style="list-style-type: decimal">
<li><p>Сума залишків моделі дорівнює нулю:
<span class="math display" id="eq:resid1">\[
\sum\limits^{n}_{i=1}u_i = 0
\tag{3.15}
\]</span></p></li>
<li><p>Вибіркова коваріація між регресорами та залишками МНК дорівнює нулю:
<span class="math display" id="eq:resid2">\[
\sum\limits^{n}_{i=1}x_iu_i = 0
\tag{3.16}
\]</span></p></li>
<li><p>Лінія регресії завжди проходить через точку <span class="math inline">\((\overline{x},\overline{y})\)</span></p></li>
<li><p>Сума значень залежної змінної дорівнює сумі модельних значень, а отже і їх середні однакові.
<span class="math display" id="eq:resid3">\[
\sum\limits^{n}_{i=1}y_i = \sum\limits^{n}_{i=1}\hat{y_i}
\tag{3.17}
\]</span>
Ці властивості притаманні кожній моделі, яка побудована з використанням МНК.</p></li>
</ol>
<p>Важливо вивести наступні поняття:</p>
<ul>
<li><p><strong>загальна сума квадратів</strong> (TSS, <em>total sum of squares</em>): оцінює дисперсію серед <span class="math inline">\(y_i\)</span>, тобто на скільки дані розсіяні у вибірці. Якщо поділити SST на <span class="math inline">\(n-1\)</span>, ми отримаємо вибіркову дисперсію значень <span class="math inline">\(y_i\)</span>.
<span class="math display" id="eq:SST">\[
TSS = \sum\limits^{n}_{i=1}(y_i - \overline{y})^2,
\tag{3.18}
\]</span></p></li>
<li><p><strong>пояснювальна сума квадратів</strong> (ESS, <em>explained/estimated sum of squares</em>): оцінює міру розсіювання <span class="math inline">\(\hat{y_i}\)</span> <a href="simple_regression.html#eq:resid3">(3.17)</a>.
<span class="math display" id="eq:SSE">\[
ESS = \sum\limits^{n}_{i=1}(\hat{y_i} - \overline{y})^2,
\tag{3.19}
\]</span></p></li>
<li><p><strong>сума квадратів залишків</strong> (RSS, <em>residual sum of squares</em>): оцінює розсіювання серед <span class="math inline">\(\hat{u_i}\)</span>.
<span class="math display" id="eq:SSR">\[
RSS = \sum\limits^{n}_{i=1}{u_i^2}
\tag{3.20}
\]</span>
TSS може визначена через суму SSE та SSR:
<span class="math display" id="eq:SST1">\[
TSS = ESS + RSS
\tag{3.21}
\]</span>
<em>Окремо зверну увагу на абрівіатури цих показників в різних джерелах:</em></p></li>
<li><p><em>TSS іноді записують, як SST.</em></p></li>
<li><p><em>ESS іноді записують, як RSS (regression sum of squares).</em></p></li>
<li><p><em>RSS іноді вживають, як SSR (sum of squared residuals) або ESS (error sum of squares).</em></p></li>
</ul>
<p><em>Будьте уважні!</em></p>
</div>
<div id="коефіцієнт-детермінації" class="section level2" number="3.3">
<h2>
<span class="header-section-number">3.3</span> Коефіцієнт детермінації<a class="anchor" aria-label="anchor" href="#%D0%BA%D0%BE%D0%B5%D1%84%D1%96%D1%86%D1%96%D1%94%D0%BD%D1%82-%D0%B4%D0%B5%D1%82%D0%B5%D1%80%D0%BC%D1%96%D0%BD%D0%B0%D1%86%D1%96%D1%97"><i class="fas fa-link"></i></a>
</h2>
<p>Тепер слід визначити, наскільки пояснювальна змінна <span class="math inline">\(x_i\)</span> пояснює пояснювальну змінну <span class="math inline">\(y_i\)</span>.</p>
<p>Якщо припустити, що TSS не дорівнює нулю (це можливо тільки в тому випадку коли всі <span class="math inline">\(y_i\)</span> однакові), ми можемо поділити <a href="simple_regression.html#eq:SST1">(3.21)</a> на TSS. В результаті, ми отримаємо <strong>коефіцієнт детермінації</strong> або <span class="math inline">\(R^2\)</span> (R-квадрат):
<span class="math display" id="eq:rsquar">\[
R^2 = \frac{ESS}{TSS} = 1 - \frac{RSS}{TSS} = 1 - \frac{\sum\limits^{n}_{i=1}{u_i^2}}{\sum\limits^{n}_{i=1}(y_i - \overline{y})^2}
\tag{3.22}
\]</span>
<span class="math inline">\(R^2\)</span> показує, яка частина варіації (розсіювання) <span class="math inline">\(y_i\)</span> пояснюється <span class="math inline">\(x_i\)</span>. Цей показник знаходиться завжди в межах від нуля до одиниці <span class="math inline">\([0,1]\)</span>. Для інтерпретації у відсотках, <span class="math inline">\(R^2\)</span> домножують на 100: <em>який відсоток варіації <span class="math inline">\(y_i\)</span> пояснюється <span class="math inline">\(x_i\)</span></em>. Чим ближчий <span class="math inline">\(R^2\)</span> до 1 - тим краще <span class="math inline">\(x_i\)</span> пояснює <span class="math inline">\(y_i\)</span> і навпаки, чим ближчий <span class="math inline">\(R^2\)</span> до 0 - тим гіршу модель ми отримали.</p>
<p>Також <span class="math inline">\(R^2\)</span> можна пояснити, як квадрат коефіцієнта кореляції між <span class="math inline">\(y_i\)</span> та <span class="math inline">\(\hat{y_i}\)</span>.</p>
<p><strong>Коефіцієнта кореляції</strong> (r, <em>correlation coefficien</em>) — показник, який показує силу лінійного взаємозв’язку між двома змінними:
<span class="math display" id="eq:corr">\[
r = \frac{n\sum\limits^{n}_{i=1}(xy) - \sum\limits^{n}_{i=1}x_i\sum\limits^{n}_{i=1}y_i}{\sqrt{[n\sum\limits^{n}_{i=1}x^2 - (\sum\limits^{n}_{i=1}x_i)^2][n\sum\limits^{n}_{i=1}y_i^2-(\sum\limits^{n}_{i=1}y_i)^2]}}
\tag{3.23}
\]</span>
<span class="math inline">\(r\)</span> змінюється від мінус одиниці до одиниці <span class="math inline">\([-1,1]\)</span>:</p>
<ul>
<li><p>при наближенні до -1 присутній обернений взаємозв’язок між змінними (одна зростає, інша спадає і навпаки)</p></li>
<li><p>при наближенні до +1 присутній прямий лінійний взаємозв’язок між змінними (одна зростає й інша зростає і навпаки)</p></li>
<li><p>при наближенні до 0 лінійного взаємозв’язку між змінними не існує.</p></li>
</ul>
<p>Для розрахунку коефіцієнта кореляції в R використовується функція <code><a href="https://rdrr.io/r/stats/cor.html">cor()</a></code>:</p>
<div class="sourceCode" id="cb149"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/stats/cor.html">cor</a></span><span class="op">(</span><span class="va">male</span><span class="op">$</span><span class="va">Weight_cm</span>, <span class="va">male</span><span class="op">$</span><span class="va">Height_kg</span><span class="op">)</span>
<span class="co">## [1] 0.8862974</span></code></pre></div>
<p>Тоді коефіцієнт детермінації має дорівнювати:</p>
<div class="sourceCode" id="cb150"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/stats/cor.html">cor</a></span><span class="op">(</span><span class="va">male</span><span class="op">$</span><span class="va">Weight_cm</span>, <span class="va">male</span><span class="op">$</span><span class="va">Height_kg</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span>
<span class="co">## [1] 0.7855231</span></code></pre></div>
<p>Давайте розрахуємо <span class="math inline">\(R^2\)</span> вручну <a href="simple_regression.html#eq:rsquar">(3.22)</a>:</p>
<div class="sourceCode" id="cb151"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fl">1</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">male_ols</span><span class="op">$</span><span class="va">residuals</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="op">(</span><span class="va">male</span><span class="op">$</span><span class="va">Weight_cm</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">male</span><span class="op">$</span><span class="va">Weight_cm</span><span class="op">)</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span>
<span class="co">## [1] 0.7855231</span></code></pre></div>
<p>Але все теж саме можна отримати застосувавши функцію <code><a href="https://rdrr.io/r/base/summary.html">summary()</a></code> до МНК моделі:</p>
<div class="sourceCode" id="cb152"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">male_ols</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
  <span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="op">)</span>
<span class="co">## </span>
<span class="co">## Call:</span>
<span class="co">## lm(formula = Weight_cm ~ Height_kg, data = male)</span>
<span class="co">## </span>
<span class="co">## Residuals:</span>
<span class="co">##     Min      1Q  Median      3Q     Max </span>
<span class="co">## -8.2309 -3.3608  0.0104  3.1405 11.6086 </span>
<span class="co">## </span>
<span class="co">## Coefficients:</span>
<span class="co">##              Estimate Std. Error t value Pr(&gt;|t|)    </span>
<span class="co">## (Intercept) -95.99872    9.50045  -10.11   &lt;2e-16 ***</span>
<span class="co">## Height_kg     1.02405    0.05405   18.95   &lt;2e-16 ***</span>
<span class="co">## ---</span>
<span class="co">## Signif. codes:  </span>
<span class="co">## 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span>
<span class="co">## </span>
<span class="co">## Residual standard error: 4.314 on 98 degrees of freedom</span>
<span class="co">## Multiple R-squared:  0.7855, Adjusted R-squared:  0.7833 </span>
<span class="co">## F-statistic: 358.9 on 1 and 98 DF,  p-value: &lt; 2.2e-16</span></code></pre></div>
<p>Функція <code><a href="https://rdrr.io/r/base/summary.html">summary()</a></code> виводить багато різноманітної інформації щодо побудованої моделі, з кожним елементом якої ми познайомимось вже згодом.</p>
<p>З точки зору інтерпретації результатів по <span class="math inline">\(R^2\)</span> слід сказати, що 78.5% варіації ваги чоловіків пояснюється їх зростом, а 21.5% пояснюються іншими показниками, які не входять у дослідження.</p>
<p>На практиці можна досить часто зустріти маленькі значення <span class="math inline">\(R^2\)</span>, але це ще не означає, що побудована модель є неефективною. Критеріїв ефективності моделей, як і задач які вони мають вирішувати досить багато, тому не слід концентруватися виключно на коефіцієнті детермінації.</p>
</div>
<div id="передумови-використання-мнк" class="section level2" number="3.4">
<h2>
<span class="header-section-number">3.4</span> Передумови використання МНК<a class="anchor" aria-label="anchor" href="#%D0%BF%D0%B5%D1%80%D0%B5%D0%B4%D1%83%D0%BC%D0%BE%D0%B2%D0%B8-%D0%B2%D0%B8%D0%BA%D0%BE%D1%80%D0%B8%D1%81%D1%82%D0%B0%D0%BD%D0%BD%D1%8F-%D0%BC%D0%BD%D0%BA"><i class="fas fa-link"></i></a>
</h2>
<p>Нагадаю, що є принципова відмінність між параметрами моделі <span class="math inline">\(\beta_j\)</span> та <span class="math inline">\(\hat{\beta_j}\)</span>:</p>
<ul>
<li><p><span class="math inline">\(\beta_j\)</span> (без “кришки”) — це істинні параметри моделі, котрі на практиці ніколи не відомі, тому що ми не маємо у розпорядженні генеральну сукупність даних щодо об’єкту дослідження. Якщо повернутися до прикладу зі зростом та вагою серед чоловіків, тоді нам потрібно було б зібрати цю інформацію для всієї чоловічої половини населення планети, але це неможливо.</p></li>
<li><p><span class="math inline">\(\hat{\beta_j}\)</span> (з “кришкою”) — це наближені оцінки параметрів моделі, які були отримані за допомогою вибірки даних. Як правило, така вибірка є випадковою, а отже і оцінки параметрів моделі є випадковими величинами.</p></li>
</ul>
<p>І тут постає питання: за яких умов ми можемо довіряти оцінкам параметрів моделі? Ці умови називають <strong>передумовами МНК</strong>:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Модель лінійна за параметрами і має коректну специфікацію.</strong> Якщо дані мають нелінійну природу та/або формула задана некоректно (про це трошки пізніше), очікувати на коректні результати від такої моделі не має сенсу.</p></li>
<li><p><strong>Випадковість вибірки даних.</strong> Якщо б в нашому прикладі з вагою і зростом були зібрана інформація тільки по високим чоловікам, то й узагальнення на основі моделі стосувалися б тільки високих чоловіків, а не всіх чоловіків планети.</p></li>
<li><p><strong>Неоднаковість та незалежність змінних <span class="math inline">\(x_i\)</span>.</strong> Явище кореляції між пояснювальними змінними називається мультиколінеарністю і вона призводить до неефективності параметрів моделі з точки зору їх інтерпретації.</p></li>
<li><p><strong>Математичне сподівання залишків моделі дорівнює нулю <span class="math inline">\(E(u_i) = 0\)</span>.</strong> Це припущення говорить по те, що серед залишків моделі будуть як позитивні, так і негативні значення, але вони компенсують один одного.</p></li>
<li><p><strong>Гомоскедастичність (постійність) залишків моделі <span class="math inline">\(Var(u_i) = \sigma^2\)</span>.</strong> Непостійність залишків призводить до значних проблем в моделі, явище гетероскедастичності (протилежність до гомоскедастичності) ми розглянемо в окремій темі.</p></li>
<li><p><strong>Незалежність залишків моделі.</strong> Якщо залишки корелюють між собою, це означає, що в них залишилась “корисна” інформація, яку наша модель не змогла визначити.</p></li>
<li><p><strong>Залишки моделі мають нормальний розподіл <span class="math inline">\(N(0, \sigma^2)\)</span>.</strong> Ця властивість буде корисною при тестуванні різноманітних гіпотез та побудові довірчих інтервалів.</p></li>
</ol>
<p>На практиці, ви досить часто будете зустрічати ситуації коли одна або одразу декілька (якщо не всі) передумов МНК не будуть виконуватись. Звичайно є альтернативні методи та моделі для побудови регресійних задач, але саме проста лінійна регресія є фундаментом, від котрого всі відштовхуються. Це як таблиця множення, розуміння і вміння нею користуватися значно полегшує подальшу роботу.</p>
</div>
<div id="значущість-оцінок-параметрів-моделі" class="section level2" number="3.5">
<h2>
<span class="header-section-number">3.5</span> Значущість оцінок параметрів моделі<a class="anchor" aria-label="anchor" href="#%D0%B7%D0%BD%D0%B0%D1%87%D1%83%D1%89%D1%96%D1%81%D1%82%D1%8C-%D0%BE%D1%86%D1%96%D0%BD%D0%BE%D0%BA-%D0%BF%D0%B0%D1%80%D0%B0%D0%BC%D0%B5%D1%82%D1%80%D1%96%D0%B2-%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D1%96"><i class="fas fa-link"></i></a>
</h2>
<p>Я вже говорив, що оцінки параметрів моделі <span class="math inline">\(\hat{\beta_0}\)</span> та <span class="math inline">\(\hat{\beta_1}\)</span> є випадковими величинами, які “приблизно” оцінюють істині параметри моделі <span class="math inline">\({\beta_0}\)</span> та <span class="math inline">\({\beta_1}\)</span>. Якщо істинні параметри моделі дорівнюють нулю, скоріш за все їх оцінки будуть дещо відхилятися від нуля і навпаки. Тож нам слід вміти визначати <strong>статистичну значущість оцінок параметрів моделі</strong> — впевненість в тому, що <strong>параметри моделі не дорівнюють нулю</strong>.</p>
<p>В якості статистичного критерію використовуються <strong>t-критерій Стьюдента</strong>:
<span class="math display" id="eq:student">\[
t_{\beta_j} = \frac{\hat{\beta_j}}{se(\hat\beta_j)},
\tag{3.24}
\]</span>
де <span class="math inline">\(se(\hat\beta_j)\)</span> — стандартна похибка <span class="math inline">\(\hat\beta_j)\)</span>, для розрахунку котрої необхідно визначити дисперсію <span class="math inline">\(\hat\beta_j)\)</span>.</p>
<p>Я залишу поза межами цього підручника доведення відповідних теорем, але якщо комусь буде цікаво ознайомитись, пропоную почитати роботи <span class="citation">(<a href="references.html#ref-wooldridge2019" role="doc-biblioref">Wooldridge 2019</a>; <a href="references.html#ref-zeileis2008" role="doc-biblioref">Kleiber 2006</a>)</span>.</p>
<p><strong>Дисперсія оцінки параметру моделі</strong> <span class="math inline">\(\hat{\beta_1}\)</span> дорівнює:
<span class="math display" id="eq:beta1var">\[
\hat{var}(\hat{\beta_1}) = \frac{S^2}{\sum\limits^{n}_{i=1}(x_i - \overline{x})^2},
\tag{3.25}
\]</span>
де
<span class="math display" id="eq:sbeta1">\[
S^2 = \frac{1}{n-2}\sum\limits^{n}_{i=1}u_i^2
\tag{3.26}
\]</span>
Корінь квадратний з <a href="simple_regression.html#eq:sbeta1">(3.26)</a> називається <strong>стандартною помилкою оцінки параметру <span class="math inline">\(\hat{\beta_1}\)</span></strong>:
<span class="math display" id="eq:sebeta1">\[
se(\hat{\beta_1}) = \sqrt{\hat{var}(\hat{\beta_1})} = \sqrt{\frac{S^2}{\sum\limits^{n}_{i=1}(x_i - \overline{x})^2}}
\tag{3.27}
\]</span></p>
<p>Аналогічним чином розраховується <strong>стандартна помилка оцінки параметру <span class="math inline">\(\hat{\beta_0}\)</span></strong>:
<span class="math display" id="eq:sebeta0">\[
se(\hat{\beta_0}) = \sqrt{\hat{var}(\hat{\beta_0})} = \sqrt{\frac{\frac{S^2}{n}\sum\limits^{n}_{i=1}x_i^2}{\sum\limits^{n}_{i=1}(x_i - \overline{x})^2}}
\tag{3.28}
\]</span>
Тепер ми знаємо, як розрахувати критерій Стьюдента <a href="simple_regression.html#eq:student">(3.24)</a>, який перевіряє значущість <span class="math inline">\(\hat{\beta_j}\)</span> за наступною процедурою:</p>
<ol style="list-style-type: decimal">
<li>Формуємо дві гіпотези:</li>
</ol>
<ul>
<li>
<span class="math inline">\(H_0:{\beta_j}=0\)</span>: параметр незначущій.</li>
<li>
<span class="math inline">\(H_1:{\beta_j}\neq 0\)</span>: параметр значущій.</li>
</ul>
<ol start="2" style="list-style-type: decimal">
<li><p>Розраховуємо критерій Стьюдента <a href="simple_regression.html#eq:student">(3.24)</a>.</p></li>
<li><p>Обираємо рівень значущості <span class="math inline">\(\alpha\)</span> — це ймовірність помилки першого роду, тобто ймовірність відхилити гіпотезу за умови, що вона правильна. На практиці <span class="math inline">\(\alpha\)</span> беруть 5% (0.05), хоча все залежить від сфери дослідження.</p></li>
<li><p>Знаходимо <em>критичне значення критерія Стьюдента</em> <span class="math inline">\(t_{df}^{\alpha/2}\)</span> для заданого рівня значущості <span class="math inline">\(\alpha\)</span> та <em>ступеня свободи</em> <span class="math inline">\(df\)</span>. Для цього використовується <a href="https://www.sjsu.edu/faculty/gerstman/StatPrimer/t-table.pdf">таблиця розподілу Стьюдента</a> або функція в R <code><a href="https://rdrr.io/r/stats/TDist.html">qt()</a></code>.</p></li>
<li><p>Порівнюємо абсолютне значення <span class="math inline">\(t_{\beta_j}\)</span> з <span class="math inline">\(t_{df}^{\alpha/2}\)</span>:</p></li>
</ol>
<ul>
<li>якщо <span class="math inline">\(|t_{\beta_j}| &gt; t_{df}^{\alpha/2}\)</span> — відхиляємо нульову гіпотезу. Це означає, що <span class="math inline">\(\beta_j\)</span> є статистично значущою і не дорівнює нулю.</li>
<li>якщо <span class="math inline">\(|t_{\beta_j}| &lt; t_{df}^{\alpha/2}\)</span> — нульова гіпотеза не може бути відхилена. Тобто <span class="math inline">\(\beta_j\)</span> є статистично незначущою.</li>
</ul>
<p>Альтернативна процедура до оцінювання статистичної значущості параметрів моделі є <strong>p-значення</strong> (читається пі-значення, <em>p-value</em>) — такий рівень значущості, за котрого гіпотеза знаходиться на межі між відхиленням і прийняттям.</p>
<p>Використовувати його дуже легко:</p>
<ul>
<li><p>якщо p-значення менше обраного рівня значущості <span class="math inline">\(\alpha\)</span> — відхиляємо нульову гіпотезу.</p></li>
<li><p>якщо p-значення більше обраного рівня значущості <span class="math inline">\(\alpha\)</span> — нульова гіпотеза не може бути відхилена.</p></li>
</ul>
</div>
<div id="довірчі-інтервали-оцінок-параметрів-моделі" class="section level2" number="3.6">
<h2>
<span class="header-section-number">3.6</span> Довірчі інтервали оцінок параметрів моделі<a class="anchor" aria-label="anchor" href="#%D0%B4%D0%BE%D0%B2%D1%96%D1%80%D1%87%D1%96-%D1%96%D0%BD%D1%82%D0%B5%D1%80%D0%B2%D0%B0%D0%BB%D0%B8-%D0%BE%D1%86%D1%96%D0%BD%D0%BE%D0%BA-%D0%BF%D0%B0%D1%80%D0%B0%D0%BC%D0%B5%D1%82%D1%80%D1%96%D0%B2-%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D1%96"><i class="fas fa-link"></i></a>
</h2>
<p><strong>Довірчий інтервал</strong> (ДІ, <em>confidence interval, CI</em>) — діапазон значень в який потрапляє випадкова величина з певною ймовірністю.</p>
<p>Довірчий інтервал для оцінок параметрів моделі розраховується за формулою:
<span class="math display" id="eq:confint">\[
\hat{\beta_j} - se(\hat{\beta_j}) \times t_{df}^{\alpha/2} &lt; \beta_j &lt; \hat{\beta_j} + se(\hat{\beta_j}) \times t_{df}^{\alpha/2}
\tag{3.29}
\]</span></p>
<p>Тобто з йомовірністю <span class="math inline">\(1 - \alpha\)</span> інтервал <span class="math inline">\((\hat{\beta_j} - se(\hat{\beta_j})*t_{df}^{\alpha/2}, \hat{\beta_j} + se(\hat{\beta_j})*t_{df}^{\alpha/2})\)</span> буде містити істинні значення параметру моделі.</p>
<p>Розрахуємо довірчі інтервали до оцінок параметрів моделі з нашого прикладу. В R для цього використовується функція <code><a href="https://rdrr.io/r/stats/confint.html">confint()</a></code>:</p>
<div class="sourceCode" id="cb153"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/stats/confint.html">confint</a></span><span class="op">(</span><span class="va">male_ols</span><span class="op">)</span>
<span class="co">##                    2.5 %     97.5 %</span>
<span class="co">## (Intercept) -114.8520605 -77.145374</span>
<span class="co">## Height_kg      0.9167876   1.131321</span></code></pre></div>
<p>Довірчі інтервали більш інформативні ніж просто точкові оцінки. Погодьтесь, що твердження “параметр <span class="math inline">\(\hat\beta_1\)</span> дорівнює 1.02405 менш інформативно, ніж”з ймовірністю 95% істинне значення параметру моделі <span class="math inline">\(\hat\beta_1\)</span> знаходиться в межах від 0.9167896 до 1.13131. Крім того, якщо довірчий інтервал перетинає нуль - це вказує на його статистичну незначущість.</p>
</div>
<div id="розрахунок-статистик-в-r" class="section level2" number="3.7">
<h2>
<span class="header-section-number">3.7</span> Розрахунок статистик в R<a class="anchor" aria-label="anchor" href="#%D1%80%D0%BE%D0%B7%D1%80%D0%B0%D1%85%D1%83%D0%BD%D0%BE%D0%BA-%D1%81%D1%82%D0%B0%D1%82%D0%B8%D1%81%D1%82%D0%B8%D0%BA-%D0%B2-r"><i class="fas fa-link"></i></a>
</h2>
<p>Повернемось до нашого прикладу з вагою і зростом.</p>
<p>Всі зазначені показники (крім довірчих інтервалів) розраховуються за допомогою функції <code><a href="https://rdrr.io/r/base/summary.html">summary()</a></code> застосованої до побудованої моделі:</p>
<div class="sourceCode" id="cb154"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">male_ols</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
  <span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="op">)</span></code></pre></div>
<ol style="list-style-type: decimal">
<li>У розділі <code>Residuals</code> наведено розподіл залишків моделі:</li>
</ol>
<pre><code>Residuals:
    Min      1Q  Median      3Q     Max 
-8.2309 -3.3608  0.0104  3.1405 11.6086 </code></pre>
<ul>
<li><p>мінімальне значення (Min): -8.2309</p></li>
<li><p>перший квартиль (1Q): -3.3608</p></li>
<li><p>медіана (Median): 0.0104</p></li>
<li><p>третій квартиль (3Q): 3.1405</p></li>
<li><p>максимальне значення (Max): 11.6086</p></li>
</ul>
<p>За бажання можна візуалізувати розподіл залишків моделі:</p>
<div class="sourceCode" id="cb156"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">male_ols</span><span class="op">$</span><span class="va">residuals</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
  <span class="fu"><a href="https://tibble.tidyverse.org/reference/as_tibble.html">as_tibble</a></span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="st">"male"</span>, y <span class="op">=</span> <span class="va">value</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> 
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_boxplot.html">geom_boxplot</a></span><span class="op">(</span>width <span class="op">=</span> <span class="fl">0.6</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/stat_summary.html">stat_summary</a></span><span class="op">(</span>
    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>label<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/sprintf.html">sprintf</a></span><span class="op">(</span><span class="st">"%1.1f"</span>, <span class="va">..y..</span><span class="op">)</span><span class="op">)</span>,
    geom <span class="op">=</span> <span class="st">"text"</span>, 
    fun <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">y</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/grDevices/boxplot.stats.html">boxplot.stats</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span><span class="op">$</span><span class="va">stats</span>,
    position <span class="op">=</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/position_nudge.html">position_nudge</a></span><span class="op">(</span>x <span class="op">=</span> <span class="fl">0.33</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="r_econometrics_files/figure-html/residplot-1.png" width="100%"></div>
<ol start="2" style="list-style-type: decimal">
<li>У розділі <code>Coefficients</code> відображається таблиця про оцінки параметрів моделі:</li>
</ol>
<pre><code>Coefficients:
             Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) -95.99872    9.50045  -10.11   &lt;2e-16 ***
Height_kg     1.02405    0.05405   18.95   &lt;2e-16 ***</code></pre>
<ul>
<li><p><code>Estimate</code>: значення оцінок параметрів</p></li>
<li><p><code>Std. Error</code>: стандартні похибки оцінок параметрів</p></li>
<li><p><code>t value</code>: значення критерію Стюдента</p></li>
<li><p><code>Pr(&gt;|t|)</code>: p-значення. Зірочки вказують на значущість параметрів моделі, що спрощує візуальне сприйняття результатів.</p></li>
</ul>
<p>Розшифровку зірочок ви можете бачити у розділі <code>Signif. codes</code>:</p>
<pre><code>Signif. codes:  
0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1</code></pre>
<ul>
<li><p><code>‘***‘</code> - p-значення наближається до нуля.</p></li>
<li><p><code>‘**‘</code> - p-значення близько 0.001</p></li>
<li><p><code>‘*‘</code> - p-значення близько 0.05</p></li>
<li><p><code>‘.‘</code> - p-значення близько 0.1</p></li>
<li><p><code>‘ ‘</code> - p-значення більше 0.1</p></li>
</ul>
<p>Останні три рядка ми розберемо згодом.</p>
</div>
<div id="точковий-та-інтервальний-прогноз" class="section level2" number="3.8">
<h2>
<span class="header-section-number">3.8</span> Точковий та інтервальний прогноз<a class="anchor" aria-label="anchor" href="#%D1%82%D0%BE%D1%87%D0%BA%D0%BE%D0%B2%D0%B8%D0%B9-%D1%82%D0%B0-%D1%96%D0%BD%D1%82%D0%B5%D1%80%D0%B2%D0%B0%D0%BB%D1%8C%D0%BD%D0%B8%D0%B9-%D0%BF%D1%80%D0%BE%D0%B3%D0%BD%D0%BE%D0%B7"><i class="fas fa-link"></i></a>
</h2>
<p>Крім пояснення сили впливу незалежної змінної на залежну, лінійна регресія дає можливість будувати прогнози. У випадку перехресних даних ми відповідаємо на питання “що-якщо?” тобто визначаємо значення <span class="math inline">\(y_{n+1}\)</span> за заданого значення <span class="math inline">\(x_{n+1}\)</span>. У випадку часових рядів - визначаємо, чому буде дорівнювати залежна змінна в наступні періоди часу.</p>
<p>Формула для розрахунку <strong>точкового прогнозу</strong>:
<span class="math display" id="eq:predict">\[
\hat{y}_{n+1} = \hat{\beta_0} + \hat{\beta_1}x_{n+1}
\tag{3.30}
\]</span>
Але й тут необхідно розраховувати довірчі інтервали до прогнозних значень. Для цього нам необхідно знати <strong>стандартну похибку пронозу</strong>:
<span class="math display" id="eq:predictCI">\[
\delta = \sqrt{S^2 (1 + \frac{1}{n} + \frac{(x_{n+1} - \overline{x})^2}{\sum\limits^{n}_{i=1}(x_i - \overline{x})^2})}
\tag{3.31}
\]</span>
Тоді <strong>прогнозний інтервал</strong>:
<span class="math display" id="eq:predictCI2">\[
\hat{y}_{n+1} - \delta*t_{df}^{\alpha/2} &lt; {y}_{n+1} &lt; \hat{y}_{n+1} + \delta*t_{df}^{\alpha/2}
\tag{3.32}
\]</span></p>
<p>Для побудови прогнозу в R використовується функція <code><a href="https://rdrr.io/r/stats/predict.html">predict()</a></code>, де необхідно вказати модель та нові значення для прогнозу.</p>
<p>В якості прикладу створимо новий датасет з тьома новими значеннями зросту для чоловіків: 186 см, 192 см та 200 см. І передамо ці значення у функцію <code><a href="https://rdrr.io/r/stats/predict.html">predict()</a></code>. В результаті для кожного нового значення отримуємо точкові прогнози:</p>
<div class="sourceCode" id="cb159"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">new_height</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html">tibble</a></span><span class="op">(</span>Height_kg <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">186</span>, <span class="fl">192</span>, <span class="fl">200</span><span class="op">)</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">male_ols</span>, newdata <span class="op">=</span> <span class="va">new_height</span><span class="op">)</span>
<span class="co">##         1         2         3 </span>
<span class="co">##  94.47537 100.61970 108.81213</span></code></pre></div>
<p>Для отримання прогнозів з довірчими інтервалами, необіхдно додатки аргумент <code>interval = "prediction"</code> до функції <code><a href="https://rdrr.io/r/stats/predict.html">predict()</a></code>. З замовчуванням будується 95% довірчий інтервал, де <code>lwr</code> та <code>upr</code> — верхня та нижня межа довірчих інтервалів.</p>
<div class="sourceCode" id="cb160"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">male_ols</span>, newdata <span class="op">=</span> <span class="va">new_height</span>, interval <span class="op">=</span> <span class="st">"prediction"</span><span class="op">)</span>
<span class="co">##         fit      lwr      upr</span>
<span class="co">## 1  94.47537 85.80017 103.1506</span>
<span class="co">## 2 100.61970 91.83835 109.4010</span>
<span class="co">## 3 108.81213 99.81929 117.8050</span></code></pre></div>
<p>Для інтерпретації результатів можна сказати, що згідно нашої моделі, 95% чоловіків зі зростом 200 сантиметрів мають вагу від 99.81929 до 117.8050 кілограмів.</p>
<p>Як альтернативу, можна використати аргумент <code>interval = "confidence"</code> для побудови <strong>довірчого інтервалу до середнього прогнозу</strong>:</p>
<div class="sourceCode" id="cb161"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">male_ols</span>, newdata <span class="op">=</span> <span class="va">new_height</span>, interval <span class="op">=</span> <span class="st">"confidence"</span><span class="op">)</span>
<span class="co">##         fit       lwr       upr</span>
<span class="co">## 1  94.47537  93.06753  95.88321</span>
<span class="co">## 2 100.61970  98.66140 102.57800</span>
<span class="co">## 3 108.81213 106.05638 111.56789</span></code></pre></div>
<p>В такому випадку інтерпретація буде наступна: згідно нашої моделі, чоловічки зі зростом 200 сантиметрів мають в середньому вагу від 106.05638 до 111.56789 кілограмів.</p>
<p>Що обрати, довірчий інтервал до середнього прогнозу чи інтервальний прогноз? Інтервальний прогнозу оцінює невизначеність щодо конкретного значення, а довірчий інтервал щодо середнього значення. Це означає, що інтервальний прогноз буде значно ширший за довірчий інтервал. Тож вибір залежить від цілей та контексту аналізу. Частіше нас цікавлять конкретні індивідуальні значення прогнозів, тож інтервальні прогнози використовуються частіше <span class="citation">(<a href="references.html#ref-bruce2017" role="doc-biblioref">Bruce and Bruce 2017</a>)</span>.</p>
<p>Наступний код демонструє різницю між довірчим інтервалом (сірий) та інтервальним прогнозом (червоний):</p>
<div class="sourceCode" id="cb162"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># 1. Будуємо прогнозні значення за моделью за реальними даними</span>
<span class="va">pred.int</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">male_ols</span>, interval <span class="op">=</span> <span class="st">"prediction"</span><span class="op">)</span>

<span class="va">male</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
  <span class="co"># 2. Об'єднуємо стовпчики</span>
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/bind.html">bind_cols</a></span><span class="op">(</span><span class="va">pred.int</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
  <span class="co"># 3. Будуємо графік</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span><span class="va">Height_kg</span>, <span class="va">Weight_cm</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span>
  <span class="co"># 4. Додаємо лінію регресії та довірчий інтервал</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_smooth.html">geom_smooth</a></span><span class="op">(</span>method <span class="op">=</span> <span class="st">"lm"</span><span class="op">)</span> <span class="op">+</span>
  <span class="co"># 5. Додаємо інтервальні прогнози</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html">geom_line</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>y <span class="op">=</span> <span class="va">lwr</span><span class="op">)</span>, color <span class="op">=</span> <span class="st">"red"</span>, linetype <span class="op">=</span> <span class="st">"dashed"</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html">geom_line</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>y <span class="op">=</span> <span class="va">upr</span><span class="op">)</span>, color <span class="op">=</span> <span class="st">"red"</span>, linetype <span class="op">=</span> <span class="st">"dashed"</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>x <span class="op">=</span> <span class="st">"Зріст (см)"</span>,
       y <span class="op">=</span> <span class="st">"Вага (кг)"</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="r_econometrics_files/figure-html/predvsconf-1.png" width="100%"></div>
</div>
<div id="завдання" class="section level2" number="3.9">
<h2>
<span class="header-section-number">3.9</span> Завдання<a class="anchor" aria-label="anchor" href="#%D0%B7%D0%B0%D0%B2%D0%B4%D0%B0%D0%BD%D0%BD%D1%8F"><i class="fas fa-link"></i></a>
</h2>
<div id="обрати-та-завантажити-дані" class="section level3" number="3.9.1">
<h3>
<span class="header-section-number">3.9.1</span> Обрати та завантажити дані<a class="anchor" aria-label="anchor" href="#%D0%BE%D0%B1%D1%80%D0%B0%D1%82%D0%B8-%D1%82%D0%B0-%D0%B7%D0%B0%D0%B2%D0%B0%D0%BD%D1%82%D0%B0%D0%B6%D0%B8%D1%82%D0%B8-%D0%B4%D0%B0%D0%BD%D1%96"><i class="fas fa-link"></i></a>
</h3>
<p>Для практичних та лабораторних робіт необхідно знайти та обрати дані з якими бажаєте працювати. Для цього рекомендую наступні джерела:</p>
<ul>
<li><p>Сервіс з пошуку даних від Google <a href="https://datasetsearch.research.google.com/">Dataset Search</a></p></li>
<li><p>Репозитарій з машинного навчання <a href="https://archive.ics.uci.edu/ml/datasets.php">UCI</a></p></li>
<li><p>Дані <a href="https://data.worldbank.org/">Всісвітнього банку</a></p></li>
<li><p>Набори даних з <a href="https://hbiostat.org/data/#vanderbilt-biostatistics-datasets">біостатистики</a></p></li>
<li><p>Платформа змагать <a href="https://www.kaggle.com/">Kaggle</a></p></li>
<li><p><a href="https://www.fueleconomy.gov/feg/download.shtml">Fuel Economy Data</a></p></li>
</ul>
<p>Вимоги до датасетів прості: мають бути цікавими для Вас та наявність числових змінних (більше двох). Можете пошукати щось додатково в гуглі.</p>
<p>Завантажте дані в R.</p>
</div>
<div id="обробка-даних" class="section level3" number="3.9.2">
<h3>
<span class="header-section-number">3.9.2</span> Обробка даних<a class="anchor" aria-label="anchor" href="#%D0%BE%D0%B1%D1%80%D0%BE%D0%B1%D0%BA%D0%B0-%D0%B4%D0%B0%D0%BD%D0%B8%D1%85"><i class="fas fa-link"></i></a>
</h3>
<p>Після завантаження даних, за потреби приведіть їх до охайного вигляду, створіть нові змінні або перекодуйте вже існуючі.</p>
</div>
<div id="лінійна-регресія" class="section level3" number="3.9.3">
<h3>
<span class="header-section-number">3.9.3</span> Лінійна регресія<a class="anchor" aria-label="anchor" href="#%D0%BB%D1%96%D0%BD%D1%96%D0%B9%D0%BD%D0%B0-%D1%80%D0%B5%D0%B3%D1%80%D0%B5%D1%81%D1%96%D1%8F"><i class="fas fa-link"></i></a>
</h3>
<p><strong>Всі завдання виконуються у двох напрямках: вручну (всі розрахунки будуєте самостійно) та за допомогою функцій мови програмування R.</strong></p>
<ol style="list-style-type: decimal">
<li><p>Оберіть дві числові змінні з завантаженого набору даних. Визначте, яка змінна буде залежною, а яка незалежною.</p></li>
<li><p>Побудуйте точкову діаграму. Як ви можете описати отриманий результат?</p></li>
<li><p>Розрахуйте коефіцієнт кореляції. Зробіть висновки.</p></li>
<li><p>Побудуйте модель простої лінійної регресії за допомогою формул та за допомогою функції <code><a href="https://rdrr.io/r/stats/lm.html">lm()</a></code>. Порівняйте результати. Запишіть рівняння регресії.</p></li>
<li><p>Відобразіть на графіку точкової діаграми лінію регресії.</p></li>
<li><p>Розрахуйте стандартні похибки оцінок параметрів моделі.</p></li>
<li><p>Розрахуйте t-критерій Стьюдента до оцінок параметрів моделі. Порівняйте з табличним значенням або розрахуйте p-значення. Зробіть висновки щодо гіпотез.</p></li>
<li><p>Побудуйте довірчі інтервали до оцінок параметрів моделі.</p></li>
<li><p>Розрахуйте коефіцієнт детермінації. Зробіть висновок щодо його значення.</p></li>
<li><p>Побудуйте точковий та інтервальний прогноз за побудованою моделью за довільними значеннями незалежної змінної.</p></li>
</ol>
</div>
</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="dplyr.html"><span class="header-section-number">2</span> Маніпуляції з даними за допомогою dplyr і не тільки</a></div>
<div class="next"><a href="multiple_regression.html"><span class="header-section-number">4</span> Множинна лінійна регресія</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>На цій сторінці</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#simple_regression"><span class="header-section-number">3</span> Проста лінійна регресія</a></li>
<li><a class="nav-link" href="#%D0%BF%D1%80%D0%BE%D1%81%D1%82%D0%B0-%D0%BB%D1%96%D0%BD%D1%96%D0%B9%D0%BD%D0%B0-%D1%80%D0%B5%D0%B3%D1%80%D0%B5%D1%81%D1%96%D1%8F"><span class="header-section-number">3.1</span> Проста лінійна регресія</a></li>
<li><a class="nav-link" href="#%D0%B2%D0%BB%D0%B0%D1%81%D1%82%D0%B8%D0%B2%D0%BE%D1%81%D1%82%D1%96-%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D1%8C%D0%BD%D0%B8%D1%85-%D0%B7%D0%BD%D0%B0%D1%87%D0%B5%D0%BD%D1%8C-%D1%82%D0%B0-%D0%B7%D0%B0%D0%BB%D0%B8%D1%88%D0%BA%D1%96%D0%B2"><span class="header-section-number">3.2</span> Властивості модельних значень та залишків</a></li>
<li><a class="nav-link" href="#%D0%BA%D0%BE%D0%B5%D1%84%D1%96%D1%86%D1%96%D1%94%D0%BD%D1%82-%D0%B4%D0%B5%D1%82%D0%B5%D1%80%D0%BC%D1%96%D0%BD%D0%B0%D1%86%D1%96%D1%97"><span class="header-section-number">3.3</span> Коефіцієнт детермінації</a></li>
<li><a class="nav-link" href="#%D0%BF%D0%B5%D1%80%D0%B5%D0%B4%D1%83%D0%BC%D0%BE%D0%B2%D0%B8-%D0%B2%D0%B8%D0%BA%D0%BE%D1%80%D0%B8%D1%81%D1%82%D0%B0%D0%BD%D0%BD%D1%8F-%D0%BC%D0%BD%D0%BA"><span class="header-section-number">3.4</span> Передумови використання МНК</a></li>
<li><a class="nav-link" href="#%D0%B7%D0%BD%D0%B0%D1%87%D1%83%D1%89%D1%96%D1%81%D1%82%D1%8C-%D0%BE%D1%86%D1%96%D0%BD%D0%BE%D0%BA-%D0%BF%D0%B0%D1%80%D0%B0%D0%BC%D0%B5%D1%82%D1%80%D1%96%D0%B2-%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D1%96"><span class="header-section-number">3.5</span> Значущість оцінок параметрів моделі</a></li>
<li><a class="nav-link" href="#%D0%B4%D0%BE%D0%B2%D1%96%D1%80%D1%87%D1%96-%D1%96%D0%BD%D1%82%D0%B5%D1%80%D0%B2%D0%B0%D0%BB%D0%B8-%D0%BE%D1%86%D1%96%D0%BD%D0%BE%D0%BA-%D0%BF%D0%B0%D1%80%D0%B0%D0%BC%D0%B5%D1%82%D1%80%D1%96%D0%B2-%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D1%96"><span class="header-section-number">3.6</span> Довірчі інтервали оцінок параметрів моделі</a></li>
<li><a class="nav-link" href="#%D1%80%D0%BE%D0%B7%D1%80%D0%B0%D1%85%D1%83%D0%BD%D0%BE%D0%BA-%D1%81%D1%82%D0%B0%D1%82%D0%B8%D1%81%D1%82%D0%B8%D0%BA-%D0%B2-r"><span class="header-section-number">3.7</span> Розрахунок статистик в R</a></li>
<li><a class="nav-link" href="#%D1%82%D0%BE%D1%87%D0%BA%D0%BE%D0%B2%D0%B8%D0%B9-%D1%82%D0%B0-%D1%96%D0%BD%D1%82%D0%B5%D1%80%D0%B2%D0%B0%D0%BB%D1%8C%D0%BD%D0%B8%D0%B9-%D0%BF%D1%80%D0%BE%D0%B3%D0%BD%D0%BE%D0%B7"><span class="header-section-number">3.8</span> Точковий та інтервальний прогноз</a></li>
<li>
<a class="nav-link" href="#%D0%B7%D0%B0%D0%B2%D0%B4%D0%B0%D0%BD%D0%BD%D1%8F"><span class="header-section-number">3.9</span> Завдання</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#%D0%BE%D0%B1%D1%80%D0%B0%D1%82%D0%B8-%D1%82%D0%B0-%D0%B7%D0%B0%D0%B2%D0%B0%D0%BD%D1%82%D0%B0%D0%B6%D0%B8%D1%82%D0%B8-%D0%B4%D0%B0%D0%BD%D1%96"><span class="header-section-number">3.9.1</span> Обрати та завантажити дані</a></li>
<li><a class="nav-link" href="#%D0%BE%D0%B1%D1%80%D0%BE%D0%B1%D0%BA%D0%B0-%D0%B4%D0%B0%D0%BD%D0%B8%D1%85"><span class="header-section-number">3.9.2</span> Обробка даних</a></li>
<li><a class="nav-link" href="#%D0%BB%D1%96%D0%BD%D1%96%D0%B9%D0%BD%D0%B0-%D1%80%D0%B5%D0%B3%D1%80%D0%B5%D1%81%D1%96%D1%8F"><span class="header-section-number">3.9.3</span> Лінійна регресія</a></li>
</ul>
</li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/aranaur/r_econometrics/blob/master/03-Simple_regression.Rmd">Переглянути код <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/aranaur/r_econometrics/edit/master/03-Simple_regression.Rmd">Редагувати <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong><span style="font-size: 14px">ОСНОВИ ЕКОНОМЕТРИКИ В R
</span></strong>", автор Ігор Мірошниченко. <br>Останні зміни: 2022-04-29.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>Книгу створено за допомогою пакету <a class="text-light" href="https://bookdown.org">bookdown</a>.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
