<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <title>04-Multiple_regression.knit</title>

  
   
   <meta name="generator" content="placeholder" />
  <meta property="og:title" content="04-Multiple_regression.knit" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="04-Multiple_regression.knit" />
  
  
  
  <!-- JS -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script>
  <script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script>
    <script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
    <link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet" />
    <script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script>
    <script src="libs/bs3compat-0.3.1/transition.js"></script>
    <script src="libs/bs3compat-0.3.1/tabs.js"></script>
    <script src="libs/bs3compat-0.3.1/bs3compat.js"></script>
    <link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet" />
    <script src="libs/bs4_book-1.0.0/bs4_book.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script>

  <!-- CSS -->
  <style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
      <link rel="stylesheet" href="style.css" />
  
</head>

<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<!--bookdown:title:start-->
<!--bookdown:title:end-->

<!--bookdown:toc:start-->
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book">
    <a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title=""></a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
      </form>

      <nav aria-label="Table of contents">
        <h2>Table of contents</h2>
        <div id="book-toc"></div>

        <div class="book-extra">
          <p><a id="book-repo" href="#">View book source <i class="fab fa-github"></i></a></li></p>
        </div>
      </nav>
    </div>
  </header>

  <main class="col-sm-12 col-md-9 col-lg-7" id="content">
<!--bookdown:toc:end-->
<!--bookdown:body:start-->
<div id="multiple_regression" class="section level1" number="1">
<h1 number="1"><span class="header-section-number">1</span> Множинна лінійна регресія</h1>
<div id="загальні-відомості" class="section level2" number="1.1">
<h2 number="1.1"><span class="header-section-number">1.1</span> Загальні відомості</h2>
<p><strong>Множинна лінійна регресія</strong> — варіант регресійної моделі, де в якості предикторів використовується більше однієї змінної. В більшості випадків це підвищує ефективність моделі в порівнянні з парною регресією.</p>
<p>Крім того, проста лінійна регресія може бути обтяжена так званим зміщенням через <strong>пропуск впливової змінної</strong> (<em>omitted variable bias</em>), що призводить до неправильних воводів у простій моделі <span class="citation">[@wooldridge2019]</span>.</p>
<p>Загальне рівняння множинної лінійної регресії:
<span class="math display">\[
y_i = \beta_0 + \beta_0x_{i,1} + \beta_0x_{i,2} + \dots + \beta_kx_{i,k} + u_i, i = 1,\dots,n
(\#eq:multreg)
\]</span>
де</p>
<ul>
<li><p><span class="math inline">\(y_i\)</span> — залежна змінна,</p></li>
<li><p><span class="math inline">\(x_{i,m}\)</span> — незалежні змінні, <span class="math inline">\(m = 1,\dots,k\)</span>,</p></li>
<li><p><span class="math inline">\(u_i\)</span> — випадкові помилки,</p></li>
<li><p><span class="math inline">\(k\)</span> — кількість незалежних змінних,</p></li>
<li><p><span class="math inline">\(n\)</span> — кількість спостережень.</p></li>
</ul>
<p>Всі передумови використання МНК залишаються тими самими, що і раніше, збільшується тільки кількість предикторів.</p>
</div>
<div id="мнк-для-множинної-регресії" class="section level2" number="1.2">
<h2 number="1.2"><span class="header-section-number">1.2</span> МНК для множинної регресії</h2>
<p>Для розрахунку оцінок параметрів моделі множинної регресії за МНК зручніше використовувати векторно-матричну форму запису.</p>
<p>Вектор значень залежної змінної:
<span class="math display">\[
Y = \begin{pmatrix}
y_1 \\
y_2 \\
\dots \\
y_{n-1} \\
y_n
\end{pmatrix}
(\#eq:y)
\]</span></p>
<p>Матриця незалежних змінних:
<span class="math display">\[
X = \begin{pmatrix}
1 &amp; x_{1,1} &amp; x_{1,2} &amp; \dots &amp; x_{1,k} \\
1 &amp; x_{2,1} &amp; x_{2,2} &amp; \dots &amp; x_{2,k} \\
\dots &amp; \dots &amp; \dots &amp; \dots &amp; \dots \\
1 &amp; x_{n,1} &amp; x_{n,2} &amp; \dots &amp; x_{n,k} \\
\end{pmatrix}
(\#eq:x)
\]</span>
Звертаю увагу, що в першому стовпчику матриці незалежних змінних записані тільки одиниці. Я дещо спрощу пояснення природи цього запису: це потрібно для розрахунку вільного параметру моделі <span class="math inline">\(\beta_0\)</span>.</p>
<p>Вектор випадкових помилок:
<span class="math display">\[
u = \begin{pmatrix}
u_1 \\
u_2 \\
\dots \\
u_{n-1} \\
u_n
\end{pmatrix}
(\#eq:u)
\]</span>
Вектор коефіцієнтів моделі:
<span class="math display">\[
\beta = \begin{pmatrix}
\beta_1 \\
\beta_1 \\
\dots \\
\beta_k
\end{pmatrix}
(\#eq:betavec)
\]</span>
Вектор оцінок коефіцієнтів моделі:
<span class="math display">\[
\hat\beta = \begin{pmatrix}
\hat\beta_1 \\
\hat\beta_1 \\
\dots \\
\hat\beta_k
\end{pmatrix}
(\#eq:betahatvec)
\]</span>
Для розрахунку МНК-оцінок параметрів моделі використовується формула:
<span class="math display">\[
\hat\beta = (X&#39;X)^{-1}X&#39;Y
(\#eq:matrixmnk)
\]</span></p>
</div>
<div id="стандартні-помилки-оцінок-параметрів-множинної-моделі" class="section level2" number="1.3">
<h2 number="1.3"><span class="header-section-number">1.3</span> Стандартні помилки оцінок параметрів множинної моделі</h2>
<p>Для розрахунку стандартних помилок оцінок параметрів множинної моделі необхідно розглянути <strong>коваріаціну матрицю коефіцієнтів моделі</strong>:
<span class="math display">\[
\hat{V}(\hat\beta) = (X&#39;X)^{-1}*S^2
(\#eq:matrixmnk)
\]</span>
де
<span class="math display">\[
S^2 = \frac{1}{n-k-1}\sum\limits^{n}_{i=1}u_i^2
(\#eq:smult)
\]</span>
Матриця <span class="math inline">\(\hat{V}(\hat\beta)\)</span> має розмір <span class="math inline">\(k+1\)</span> на <span class="math inline">\(k+1\)</span>, де на перетині <span class="math inline">\(i\)</span>-го рядку та <span class="math inline">\(j\)</span>-го стовпчика знаходиться незміщенна оцінка коефіцієнта коваріації між <span class="math inline">\(\hat\beta_i\)</span> та <span class="math inline">\(\hat\beta_j\)</span>.</p>
<p>З матриці <span class="math inline">\(\hat{V}(\hat\beta)\)</span> нас цікваить головна діагональ, оскільки на ній міститься незміщенна дисперсія оцінок параметрів моделі. <em>Корінь квадратний з елементів головної діагоналі</em> — це <strong>стандартні похибки оцінок параметрів моделі</strong>:
<span class="math display">\[
se(\hat\beta_j) = \sqrt{\hat{V_{jj}}} = \sqrt{\hat{var}(\hat\beta_j)}
(\#eq:sebetamult)
\]</span></p>
</div>
<div id="значущість-оцінок-параметрів-моделі" class="section level2" number="1.4">
<h2 number="1.4"><span class="header-section-number">1.4</span> Значущість оцінок параметрів моделі</h2>
<p>Даний етап виконується аналогічно до парної регресії.</p>
</div>
<div id="скорегований-коефіцієнт-детермінації" class="section level2" number="1.5">
<h2 number="1.5"><span class="header-section-number">1.5</span> Скорегований коефіцієнт детермінації</h2>
<p>Розрахунок та інтерпретація коефіцієнту детермінації залишається аналогічним до простої лінійної регресії @ref(eq:rsquar).</p>
<p>Проте <span class="math inline">\(R^2\)</span> має суттєву особливість в множинній регресії: він характеризує наявність кореляції між незалежними і залежною змінною, але <strong>нічного не говорить про причинно-наслідкові зв’язки</strong>. Тому <span class="math inline">\(R^2\)</span> <strong>не може бути використаний для порівняння простих і більш складних (з більшою кількістю незалежних змінних) моделей</strong>.</p>
<p>Але є значна <strong>проблема</strong>: додавання нових змінних до спеицифікації моделі призводить до збільшення <span class="math inline">\(R^2\)</span>. В деяких випадках він може залишитися незмінним, але точно не зменшитися. Це означає, що якщо бездумно додавати будь-які змінні в модель, вона може ставати кращою, але це оманливе відчуття.</p>
<p>Щоб продемонструвати цю проблему:
- згенеруємо 10000 значень <span class="math inline">\(y\)</span>
- згенеруємо 10000 значень для кожної змінної від <span class="math inline">\(x_1\)</span> до <span class="math inline">\(x_{1000}\)</span>
- побудуємо моделі регресії:
- <span class="math inline">\(LM_1\)</span>: Регресія <span class="math inline">\(y\)</span> на даних <span class="math inline">\(x_1\)</span>
- <span class="math inline">\(LM_2\)</span>: Регресія <span class="math inline">\(y\)</span> на даних <span class="math inline">\(x_2\)</span>
- <span class="math inline">\(\dots\)</span>
- <span class="math inline">\(LM_{1000}\)</span>: Регресія <span class="math inline">\(y\)</span> на даних <span class="math inline">\(x_{1000}\)</span>
- до кожної моделі розрахуємо <span class="math inline">\(R^2\)</span> і подивимось на динаміку його зміни.</p>
<p>Зауважу, що жодного зв’язку між <span class="math inline">\(y\)</span> та <span class="math inline">\(x_k\)</span> не має.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="fl">1e4</span>)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="at">data =</span> <span class="fu">rnorm</span>(<span class="fl">1e7</span>), <span class="at">nrow =</span> <span class="fl">1e4</span>)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>x <span class="sc">%&lt;&gt;%</span> <span class="fu">cbind</span>(<span class="fu">matrix</span>(<span class="at">data =</span> <span class="dv">1</span>, <span class="at">nrow =</span> <span class="fl">1e4</span>, <span class="at">ncol =</span> <span class="dv">1</span>), x)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>r_df <span class="ot">&lt;-</span> <span class="fu">mclapply</span>(<span class="at">X =</span> <span class="dv">1</span><span class="sc">:</span>(<span class="fl">1e3</span><span class="dv">-1</span>), <span class="at">FUN =</span> <span class="cf">function</span>(i) {</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>  tmp_reg <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x[,<span class="dv">1</span><span class="sc">:</span>(i<span class="sc">+</span><span class="dv">1</span>)]) <span class="sc">%&gt;%</span> <span class="fu">summary</span>()</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">data.frame</span>(</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">k =</span> i <span class="sc">+</span> <span class="dv">1</span>,</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">r2 =</span> tmp_reg <span class="sc">%$%</span> r.squared,</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>    <span class="at">r2_adj =</span> tmp_reg <span class="sc">%$%</span> adj.r.squared</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>}) <span class="sc">%&gt;%</span> <span class="fu">bind_rows</span>()</span></code></pre></div>
<p><img src="04-Multiple_regression_files/figure-html/r2%20plot-1.svg" width="100%" /></p>
<p>В таких випадках пропонують використовувати вдосконалену версію <span class="math inline">\(R^2\)</span> — <strong>скорегований коефіцієнт детермінації</strong> (<em>adjusted <span class="math inline">\(R^2\)</span></em>):
<span class="math display">\[
R_{adj}^2 = 1 - (1 - R^2)\left [  \frac{(n-1)}{(n-k-1)} \right ]
(\#eq:adjrsquer)
\]</span>
В порівнянні з класичним <span class="math inline">\(R^2\)</span>, його модифікація <span class="math inline">\(R_{adj}^2\)</span> штрафується на кількість змінних. Якщо додавати в модель предиктори, які не приносять суттєвого вкладу в пояснення залежної змінної, <span class="math inline">\(R_{adj}^2\)</span> буде зменшуватися.</p>
<p><img src="04-Multiple_regression_files/figure-html/adjusted%20r2%20plot-1.svg" width="100%" /></p>
<!-- Давайте до нашого прикладу з вагою і зростом чоловіків додамо три випадкові змінні: -->
<!-- ```{r adj} -->
<!-- set.seed(2022) -->
<!-- male %>%  -->
<!--   mutate(Random1 = runif(100, 0, 100), -->
<!--          Random2 = runif(100, 0, 100), -->
<!--          Random3 = runif(100, 0, 100)) %>% -->
<!--   lm(Weight_cm ~ Height_kg + Random1 + Random2 + Random3, data = .) %>%  -->
<!--   summary() -->
<!-- ``` -->
<!-- Тоді, якщо порівняти коефіцієнти детермінації простої лінійної моделі та множинної моделі з декількома випадковими змінними, можна побачити, що $R^2$ збільшився, проте $R_{adj}^2$ дещо зменшився. В даному випадку доцільніше використовувати саме просту модель. -->
<!-- ``` -->
<!-- 1. Weight_cm ~ Height_kg -->
<!-- Multiple R-squared:  0.7855,   Adjusted R-squared:  0.7833 -->
<!-- 2. Weight_cm ~ Height_kg + Random1 + Random2 + Random3 -->
<!-- Multiple R-squared:  0.7914,   Adjusted R-squared:  0.7826  -->
<p>```</p>
<p>bookdown::render_book(“index.Rmd”, output_dir = “docs”)</p>
</div>
</div>
<!--bookdown:body:end-->
  </main>

  <div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page">
      <h2>On this page</h2>
      <div id="book-on-this-page"></div>

      <div class="book-extra">
        <ul class="list-unstyled">
          <li><a id="book-source" href="#">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="#">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
      </div>
    </nav>
  </div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5">
  <div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong></strong>" was written by . </p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer>


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
<script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>

</html>
